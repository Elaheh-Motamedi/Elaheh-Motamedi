# Hi, Iâ€™m Elaheh Motamedi ðŸ‘‹
PhD candidate in Electrical & Computer Engineering focused on computer vision, multimodal learning (video/audio/WiFi), and robotics. I design robust Transformerâ€‘based systems and deploy models for realâ€‘time applications using CUDA/ONNX/TensorRT. I value clean, reproducible research and practical impact.

# About me
- 5+ years building and shipping ML/CV models on structured & unstructured data, including real-time deployment on edge devices
- **Published researcher** in top-tier venues including Nature Scientific Data and IEEE conferences
- **Competition winner**: 1st place at ACC 2023 self-driving car competition with custom YOLO system
- **Teaching experience**: Mentored 240+ students in FPGA and digital design as Graduate TA
- **Specialized in**: multimodal fusion, WiFi sensing, adversarial robustness, and model optimization for resource-constrained environments
- **Full-stack ML**: data pipelines â†’ modeling â†’ evaluation â†’ deployment (achieved 2Ã— speedup on Intel NCS2, 10Ã— on NVIDIA Jetson)

# Education

PhD in Electrical and Computer Engineering at Northeastern University, Boston (Expected:2026)

# Skills & Technologies

- **Programming**: Python, MATLAB, Julia, CUDA

- **ML/DL**: PyTorch, TensorFlow, Keras, scikitâ€‘learn, Hugging Face Transformers, XGBoost,  Reinforcement Learning,  Natural Language Processing (NLP), Timeâ€‘series (RNN/LSTM/GRU/GCN), Ensembles, SVM, Clustering/Dim. Reduction (kâ€‘means, PCA), LLMs (Large Language Models)

- **Computer Vision**: OpenCV, scikitâ€‘image, YOLO, Faster Râ€‘CNN, Vision Transformers (ViT, TimeSformer, SlowFast), Object Detection, segmentation, optical flow, feature matching, 3D

- **Data & Viz**: NumPy, pandas, Matplotlib, Seaborn, Tableau, LaTeX

- **Optimization & Deployment**: ONNX, TensorRT, CUDA, MLOps basics

- **Tools**: Git, VS Code, Jupyter, Linux, HPC
  
## Contact


- **Email:**  [motamedi.e@northeastern.edu](mailto:motamedi.e@northeastern.edu) Â· [elahe.motamedi@gmail.com](mailto:elahe.motamedi@gmail.com)
- **LinkedIn:** [Ella-motamedi](https://www.linkedin.com/in/ella-motamedi)
- **Google Scholar:** [Elaheh Motamedi](https://scholar.google.com/citations?user=bBWGrGQAAAAJ)




<!-- # Selected projects

TriSenseBandit â€” Multimodal Transformer + contextual bandit for robust robot action recognition (adapts which modality to trust).

LEâ€‘MvDA â€” Locally Enhanced Multiâ€‘view Discriminant Analysis for crossâ€‘view classification (IEEE Access R&R).

Eventâ€‘camera pipelines â€” Prophesee EVK4: voxelâ€‘grid encoding â†’ CNN/ViT; evaluation under APGD/FGSM; darkâ€‘scene motion capture.

RoboMNIST â€” Dataset and training code for video+audio+WiFi with logitâ€‘level fusion and early stopping.

Links to code/papers coming soon. Ping me if you need early access. 
# Featured Projects
- **[LE-MvDA](https://github.com/Elaheh-Motamedi/LE-MvDA)** - Lightweight interpretable multi-view dimensionality reduction algorithm outperforming deep learning models
- **[QuanserCompetition](https://github.com/Elaheh-Motamedi/QuanserCompetition)** - Enhanced YOLO object detection system (92.7% accuracy, ðŸ† 1st place ACC 2023)
- **RoboFiSense Dataset** - WiFi-based robotic activity recognition framework achieving 92.5% accuracy
- **TriSenseFormer** - Multimodal Transformer (WiFi+video+audio) with 98.3% accuracy and robust performance under data corruption
**Elaheh-Motamedi/Elaheh-Motamedi** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
