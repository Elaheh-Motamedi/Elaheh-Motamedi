# Hi, Iâ€™m Elaheh Motamedi ðŸ‘‹
PhD candidate in Electrical & Computer Engineering focused on computer vision, multimodal learning (video/audio/WiFi), and robotics. I design robust Transformerâ€‘based systems and deploy models for realâ€‘time applications using CUDA/ONNX/TensorRT. I value clean, reproducible research and practical impact.

# About me

- 5+ years building and shipping ML/CV models on structured & unstructured data

- Strengths: multimodal fusion, event cameras, robustness (noise/missing modalities)

- Comfortable across the stack: data pipelines â†’ modeling â†’ evaluation â†’ deployment

# Education

PhD in Electrical and Computer Engineering at Northeastern University, Boston (Expected:2026)

# Skills & Technologies

- **Programming**: Python, MATLAB, Julia, CUDA

- **ML/DL**: PyTorch, TensorFlow, Keras, scikitâ€‘learn, Hugging Face Transformers, XGBoost,  Reinforcement Learning,  Natural Language Processing (NLP), Timeâ€‘series (RNN/LSTM/GRU/GCN), Ensembles, SVM, Clustering/Dim. Reduction (kâ€‘means, PCA), LLMs (Large Language Models)

- **Computer Vision**: OpenCV, scikitâ€‘image, YOLO, Faster Râ€‘CNN, Vision Transformers (ViT, TimeSformer, SlowFast), Object Detection, segmentation, optical flow, feature matching, 3D

- **Data & Viz**: NumPy, pandas, Matplotlib, Seaborn, Tableau, LaTeX

- **Optimization & Deployment**: ONNX, TensorRT, CUDA, MLOps basics

- **Tools**: Git, VS Code, Jupyter, Linux, HPC
  
## Contact


- **Email:** [elahe.motamedi@gmail.com](mailto:elahe.motamedi@gmail.com) Â· [motamedi.e@northeastern.edu](mailto:motamedi.e@northeastern.edu)
- **LinkedIn:** [ella-motamedi](https://www.linkedin.com/in/ella-motamedi)
- **Google Scholar:** [Elaheh Motamedi](https://scholar.google.com/citations?user=bBWGrGQAAAAJ)




<!-- # Selected projects

TriSenseBandit â€” Multimodal Transformer + contextual bandit for robust robot action recognition (adapts which modality to trust).

LEâ€‘MvDA â€” Locally Enhanced Multiâ€‘view Discriminant Analysis for crossâ€‘view classification (IEEE Access R&R).

Eventâ€‘camera pipelines â€” Prophesee EVK4: voxelâ€‘grid encoding â†’ CNN/ViT; evaluation under APGD/FGSM; darkâ€‘scene motion capture.

RoboMNIST â€” Dataset and training code for video+audio+WiFi with logitâ€‘level fusion and early stopping.

Links to code/papers coming soon. Ping me if you need early access. 
**Elaheh-Motamedi/Elaheh-Motamedi** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
